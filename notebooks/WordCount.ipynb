{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Wordcount with Rheem <div style=\"float:right; z-index:1\"><img src=\"rheem.png\" width=\"100px\" /></div></h1>\n",
    "\n",
    "This notebook demonstrates how to run Wordcount, the _Hello world!_ for data processing tools. To run this notebook, you will need the [Jupyter Scala kernel](https://github.com/alexarchambault/jupyter-scala)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36moffline\u001b[39m: \u001b[32mBoolean\u001b[39m = \u001b[32mfalse\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val offline = false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we obtain an input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locally {\n",
    "    import java.io._\n",
    "    import scala.io.Source\n",
    "    \n",
    "    val file = new File(\"data/iliad.txt\")\n",
    "    if (!file.exists) {\n",
    "        file.getParentFile.mkdirs()\n",
    "        val source = Source.fromURL(\"http://www.gutenberg.org/cache/epub/6130/pg6130.txt\")\n",
    "        val writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file), \"UTF-8\"))\n",
    "        source.foreach(char => writer.write(char.asInstanceOf[Int]))\n",
    "        writer.close()\n",
    "        source.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we intialize Rheem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/Users/basti/.coursier/cache/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-nop/1.7.12/slf4j-nop-1.7.12.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/Users/basti/.m2/repository/org/slf4j/slf4j-simple/1.7.13/slf4j-simple-1.7.13.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.helpers.NOPLoggerFactory]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                           ,\n",
       "    $ivy.$                                        ,\n",
       "    $ivy.$                                          ,\n",
       "    $ivy.$                                         ,\n",
       "    $ivy.$                                          ,\n",
       "    $ivy.$                                                   \n",
       "\n",
       "// Do the relevant imports.\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.qcri.rheem.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.qcri.rheem.core.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.qcri.rheem.core.optimizer.ProbabilisticDoubleInterval\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.qcri.rheem.java.Java, org.qcri.rheem.spark.Spark\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.github.sekruse.spark_summit_demo._\n",
       "\n",
       "// Set up a Rheem context.\n",
       "\u001b[39m\n",
       "\u001b[36mlocalDir\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mio\u001b[39m.\u001b[32mFile\u001b[39m = /Users/basti/Work/Repositories/spark-summit-2017/notebooks/.\n",
       "\u001b[36mconfig\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mqcri\u001b[39m.\u001b[32mrheem\u001b[39m.\u001b[32mcore\u001b[39m.\u001b[32mapi\u001b[39m.\u001b[32mConfiguration\u001b[39m = Configuration[file:///Users/basti/Work/Repositories/spark-summit-2017/notebooks/./rheem.properties]\n",
       "\u001b[36mrheemCtx\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mqcri\u001b[39m.\u001b[32mrheem\u001b[39m.\u001b[32mcore\u001b[39m.\u001b[32mapi\u001b[39m.\u001b[32mRheemContext\u001b[39m = org.qcri.rheem.core.api.RheemContext@3ab6fb"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Load dependencies into the kernel.\n",
    "import $ivy.`org.slf4j:slf4j-nop:1.7.12`,\n",
    "    $ivy.`org.qcri.rheem:rheem-api:0.2.1-SNAPSHOT`,\n",
    "    $ivy.`org.qcri.rheem:rheem-basic:0.2.1-SNAPSHOT`,\n",
    "    $ivy.`org.qcri.rheem:rheem-java:0.2.1-SNAPSHOT`,\n",
    "    $ivy.`org.qcri.rheem:rheem-spark:0.2.1-SNAPSHOT`,\n",
    "    $ivy.`com.github.sekruse::spark-summit-demo:1.0-SNAPSHOT`\n",
    "\n",
    "// Do the relevant imports.\n",
    "import org.qcri.rheem.api._\n",
    "import org.qcri.rheem.core.api._\n",
    "import org.qcri.rheem.core.optimizer.ProbabilisticDoubleInterval\n",
    "import org.qcri.rheem.java.Java, org.qcri.rheem.spark.Spark\n",
    "import com.github.sekruse.spark_summit_demo._\n",
    "\n",
    "// Set up a Rheem context.\n",
    "val localDir = new java.io.File(\".\").getAbsoluteFile\n",
    "val config = new Configuration(s\"file://$localDir/rheem.properties\")\n",
    "val rheemCtx = new RheemContext(config) withPlugin Java.basicPlugin withPlugin Spark.basicPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (offline) {\n",
    "    requireJs(\"plotly\", \"http://localhost:8889/js/plotly-latest.min\")\n",
    "} else {\n",
    "    requireJs(\"plotly\", \"https://cdn.plot.ly/plotly-latest.min\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can do the Wordcount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({\n",
       "    paths: {\"plotly\":\"https://cdn.plot.ly/plotly-latest.min\"}\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"my-div-0\" style=\"width: 100%; height: 100%\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "require(['plotly'], function(plotly) {\n",
       "    // Inputs:\n",
       "    var data = [{\"name\":\"Words in Homer's Iliad\",\"hoverinfo\":\"label+value+percent\",\"labels\":[\"a\",\"d\",\"in\",\"their\",\"the\",\"that\",\"with\",\"as\",\"his\",\"s\",\"and\",\"of\",\"(other)\",\"from\",\"to\",\"he\",\"on\"],\"values\":[2353.0,3250.0,3189.0,1053.0,15798.0,1049.0,2462.0,1054.0,3467.0,1521.0,7154.0,5240.0,143026.0,1429.0,4488.0,1722.0,1311.0],\"type\":\"pie\",\"showlegend\":false}],\n",
       "        divId = \"my-div-0\";\n",
       "    plotly.newPlot(divId, data);\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "locally {\n",
    "    // Define a class to handle word counts neatly.\n",
    "    case class WC(word: String, count: Int) {\n",
    "        def +(that: WC) = {\n",
    "            require(this.word == that.word)\n",
    "            WC(this.word, this.count + that.count)\n",
    "        }\n",
    "        \n",
    "        override def toString: String = s\"${count}x ${word}\"\n",
    "    }\n",
    "    \n",
    "    // Set up a new plan.\n",
    "    val planBuilder = new PlanBuilder(rheemCtx)\n",
    "        .withJobName(\"WordCount\")\n",
    "        .withUdfJarsOf(this.getClass)\n",
    "    \n",
    "    val wordCounts = planBuilder\n",
    "\n",
    "        // Read the text file.\n",
    "        .readTextFile(s\"file://$localDir/data/iliad.txt\").withName(\"Load file\")\n",
    "\n",
    "        // Split each line by non-word characters.\n",
    "        .flatMap(_.split(\"\\\\W+\")).withName(\"Split words\")\n",
    "\n",
    "        // Filter empty tokens.\n",
    "        .filter(_.nonEmpty, selectivity = 0.99).withName(\"Filter empty words\")\n",
    "\n",
    "        // Attach counter to each word.\n",
    "        .map(word => WC(word.toLowerCase, 1)).withName(\"To lower case, add counter\")\n",
    "\n",
    "        // Sum up counters for every word.\n",
    "        .reduceByKey(_.word, _ + _).withName(\"Add counters\")\n",
    "        .withCardinalityEstimator((in: Long) => math.round(in * 0.01))\n",
    "    \n",
    "        // Mask rather small words counts.\n",
    "        .map(wc => if (wc.count > 1000) wc else WC(\"(other)\", wc.count)).withName(\"Mask rather small words\")\n",
    "        .reduceByKey(_.word, _ + _).withName(\"Add counters again\")\n",
    "\n",
    "        // Execute the plan and collect the results.\n",
    "        .collect()\n",
    "    \n",
    "    plotPieChart[WC](\n",
    "        name = \"Words in Homer's Iliad\",\n",
    "        data = wordCounts,\n",
    "        values = _.count.toDouble,\n",
    "        labels = _.word,\n",
    "        showlegend = false\n",
    "    )\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
